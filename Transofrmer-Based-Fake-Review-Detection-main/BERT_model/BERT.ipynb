{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T04:31:26.84014Z",
     "iopub.status.busy": "2024-10-27T04:31:26.838924Z",
     "iopub.status.idle": "2024-10-27T04:31:30.099436Z",
     "shell.execute_reply": "2024-10-27T04:31:30.098439Z",
     "shell.execute_reply.started": "2024-10-27T04:31:26.84008Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install transformers pandas torch\n",
    "!pip install datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_excel(\"/kaggle/input/labelled-dataset/Label.xlsx\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T04:31:38.26177Z",
     "iopub.status.busy": "2024-10-27T04:31:38.260686Z",
     "iopub.status.idle": "2024-10-27T04:32:03.948567Z",
     "shell.execute_reply": "2024-10-27T04:32:03.94764Z",
     "shell.execute_reply.started": "2024-10-27T04:31:38.261721Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from datasets import Dataset\n",
    "\n",
    "#Convert into huggingFace dataset\n",
    "hf_train_dataset = Dataset.from_pandas(train_df)\n",
    "hf_test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "# Apply the mapping to the dataset\n",
    "hf_train_dataset = hf_train_dataset.map(lambda examples: {'label': label_mapping[examples['label']]})\n",
    "hf_test_dataset = hf_test_dataset.map(lambda examples: {'label': label_mapping[examples['label']]})\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text_\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "# Tokenize the training and testing datasets\n",
    "tokenized_train_dataset = hf_train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_test_dataset = hf_test_dataset.map(tokenize_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T04:33:30.732507Z",
     "iopub.status.busy": "2024-10-27T04:33:30.731844Z",
     "iopub.status.idle": "2024-10-27T04:34:17.744147Z",
     "shell.execute_reply": "2024-10-27T04:34:17.743104Z",
     "shell.execute_reply.started": "2024-10-27T04:33:30.732467Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataset = tokenized_train_dataset.shuffle(seed=42) \n",
    "eval_dataset = tokenized_test_dataset.shuffle(seed=42)  \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Convert small_train_dataset to a pandas DataFrame\n",
    "train_df = pd.DataFrame(train_dataset)\n",
    "eval_df = pd.DataFrame(eval_dataset)\n",
    "\n",
    "train_df.to_csv('train_dataset.csv', index=False)\n",
    "eval_df.to_csv('eval_dataset.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T04:34:33.908598Z",
     "iopub.status.busy": "2024-10-27T04:34:33.908188Z",
     "iopub.status.idle": "2024-10-27T04:34:37.29572Z",
     "shell.execute_reply": "2024-10-27T04:34:37.294975Z",
     "shell.execute_reply.started": "2024-10-27T04:34:33.90856Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T04:34:41.475629Z",
     "iopub.status.busy": "2024-10-27T04:34:41.474591Z",
     "iopub.status.idle": "2024-10-27T04:34:54.291992Z",
     "shell.execute_reply": "2024-10-27T04:34:54.2909Z",
     "shell.execute_reply.started": "2024-10-27T04:34:41.475586Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T05:53:22.749459Z",
     "iopub.status.busy": "2024-10-27T05:53:22.749033Z",
     "iopub.status.idle": "2024-10-27T06:44:18.2014Z",
     "shell.execute_reply": "2024-10-27T06:44:18.200495Z",
     "shell.execute_reply.started": "2024-10-27T05:53:22.749417Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "    \n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"test_trainer\",           \n",
    "    eval_strategy=\"epoch\",         \n",
    "    per_device_train_batch_size=16,      \n",
    "    per_device_eval_batch_size=16,       \n",
    "    num_train_epochs=2,                  \n",
    "    save_steps=10_000,                   \n",
    "    save_total_limit=2,                \n",
    "    logging_dir=\"logs\",               \n",
    "    logging_steps=500,                   \n",
    ")\n",
    "\n",
    "    \n",
    "# You would then initialize the Trainer with your model and datasets\n",
    "trainer = Trainer(\n",
    "    model=model,                         \n",
    "    args=training_args,                  \n",
    "    train_dataset=train_dataset,        \n",
    "    eval_dataset=eval_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T06:44:41.483438Z",
     "iopub.status.busy": "2024-10-27T06:44:41.48304Z",
     "iopub.status.idle": "2024-10-27T06:46:46.075688Z",
     "shell.execute_reply": "2024-10-27T06:46:46.074749Z",
     "shell.execute_reply.started": "2024-10-27T06:44:41.4834Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T06:47:02.408432Z",
     "iopub.status.busy": "2024-10-27T06:47:02.407539Z",
     "iopub.status.idle": "2024-10-27T06:47:03.536596Z",
     "shell.execute_reply": "2024-10-27T06:47:03.535647Z",
     "shell.execute_reply.started": "2024-10-27T06:47:02.408389Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "# Assuming 'model' is your trained model\n",
    "model.save_pretrained('/kaggle/working/Prediction_model')  \n",
    "\n",
    "# Save the tokenizer as well\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')  \n",
    "tokenizer.save_pretrained('/kaggle/working/Prediction_model')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T06:47:09.144262Z",
     "iopub.status.busy": "2024-10-27T06:47:09.143414Z",
     "iopub.status.idle": "2024-10-27T06:47:09.454099Z",
     "shell.execute_reply": "2024-10-27T06:47:09.453194Z",
     "shell.execute_reply.started": "2024-10-27T06:47:09.144213Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/kaggle/working/Prediction_model\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"/kaggle/working/Prediction_model\").to(device)\n",
    "\n",
    "# Test with new input\n",
    "input_text = \"\"\"Anyone expecting some miracle tool... this is it.  Not too big or too small, but just what I wanted.  The plastic parts are solid and the plastic is solid.  The metal part is well made and will last a long time.  This is an excellent product.  I highly recommend.Works great. I installed it in the kitchen and it works great. I installed it in my dining room and it works great.Great.  I like that the spring is\"\"\"\n",
    "# Tokenize the input\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)\n",
    "\n",
    "# Get prediction\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "logits = outputs.logits\n",
    "predicted_class = logits.argmax(-1).item()\n",
    "\n",
    "\n",
    "\n",
    "# Interpret the result\n",
    "if predicted_class == 0:\n",
    "    print(\"Computer generated Review\")\n",
    "else:\n",
    "    print(\"Original Review\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T06:47:14.875978Z",
     "iopub.status.busy": "2024-10-27T06:47:14.875587Z",
     "iopub.status.idle": "2024-10-27T06:47:38.334609Z",
     "shell.execute_reply": "2024-10-27T06:47:38.333659Z",
     "shell.execute_reply.started": "2024-10-27T06:47:14.87594Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Zip the saved model directory\n",
    "!zip -r /kaggle/working/Prediction_model.zip /kaggle/working/Prediction_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T06:48:33.648337Z",
     "iopub.status.busy": "2024-10-27T06:48:33.647606Z",
     "iopub.status.idle": "2024-10-27T06:48:33.705969Z",
     "shell.execute_reply": "2024-10-27T06:48:33.705207Z",
     "shell.execute_reply.started": "2024-10-27T06:48:33.648291Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load the tokenizer from the saved directory\n",
    "tokenizer = BertTokenizer.from_pretrained('/kaggle/working/Prediction_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T08:43:20.883894Z",
     "iopub.status.busy": "2024-10-27T08:43:20.883568Z",
     "iopub.status.idle": "2024-10-27T08:43:21.140756Z",
     "shell.execute_reply": "2024-10-27T08:43:21.139887Z",
     "shell.execute_reply.started": "2024-10-27T08:43:20.883861Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the evaluation dataset (adjust the file path if necessary)\n",
    "eval_data = pd.read_csv('/kaggle/working/eval_dataset.csv')\n",
    "\n",
    "# Assuming 'review' column has the review text and 'label' has the true labels\n",
    "texts = eval_data['text_'].tolist()\n",
    "true_labels = eval_data['label'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T07:46:17.407158Z",
     "iopub.status.busy": "2024-10-27T07:46:17.406463Z",
     "iopub.status.idle": "2024-10-27T08:43:20.881805Z",
     "shell.execute_reply": "2024-10-27T08:43:20.880734Z",
     "shell.execute_reply.started": "2024-10-27T07:46:17.407117Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Load the tokenizer and the model\n",
    "model_path = '/kaggle/working/Prediction_model'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "# Tokenize the evaluation dataset in batches\n",
    "batch_size = 100  # Adjust this size based on your memory limits\n",
    "predicted_labels = []\n",
    "\n",
    "for i in range(0, len(texts), batch_size):\n",
    "    batch_texts = texts[i:i+batch_size]\n",
    "    inputs = tokenizer(batch_texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # Convert logits to predicted labels\n",
    "    batch_predictions = torch.argmax(outputs.logits, axis=1).numpy()\n",
    "    predicted_labels.extend(batch_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T09:03:46.357814Z",
     "iopub.status.busy": "2024-10-27T09:03:46.357431Z",
     "iopub.status.idle": "2024-10-27T09:03:46.373986Z",
     "shell.execute_reply": "2024-10-27T09:03:46.372927Z",
     "shell.execute_reply.started": "2024-10-27T09:03:46.357779Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "TN, FP, FN, TP = cm.ravel()\n",
    "cm_table = pd.DataFrame(\n",
    "    {\n",
    "        'Predicted True': [TP, FP],\n",
    "        'Predicted False': [FN, TN]\n",
    "    },\n",
    "    index=['Actual True', 'Actual False']\n",
    ")\n",
    "\n",
    "print(cm_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T09:03:49.221592Z",
     "iopub.status.busy": "2024-10-27T09:03:49.220839Z",
     "iopub.status.idle": "2024-10-27T09:03:49.79504Z",
     "shell.execute_reply": "2024-10-27T09:03:49.794015Z",
     "shell.execute_reply.started": "2024-10-27T09:03:49.221548Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-27T09:11:03.284893Z",
     "iopub.status.busy": "2024-10-27T09:11:03.283976Z",
     "iopub.status.idle": "2024-10-27T09:11:03.309756Z",
     "shell.execute_reply": "2024-10-27T09:11:03.308632Z",
     "shell.execute_reply.started": "2024-10-27T09:11:03.284838Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(true_labels, predicted_labels, target_names=['Computer Generated', 'Original'])\n",
    "print(report)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5969618,
     "sourceId": 9750529,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 140836,
     "modelInstanceId": 117605,
     "sourceId": 138870,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 141565,
     "modelInstanceId": 118324,
     "sourceId": 139715,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 148314,
     "modelInstanceId": 125332,
     "sourceId": 147698,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
